<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>paper</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>River runoff is an important component of the global water cycle as it comprises about one third of the precipitation over land areas <span class="citation" data-cites="hagemannHighResolutionDischarge2020">[@hagemannHighResolutionDischarge2020]</span>. In the context of climate change studies, river runoff is usually generated in two ways. First, river runoff as input for ocean models can be created using hyrdological models such as the Hydrological Discharge (HD) model <span class="citation" data-cites="hagemannHighResolutionDischarge2020">[@hagemannHighResolutionDischarge2020]</span>. HD models calculates the water balance using hydrological processes (e.g.&nbsp;snow, glaciers, soil moisture, groundwater contribution). It represents a complex forecasting tool that uses underlying physical processes. A different approach would use data-based models that intergrate statistical correction, using the land surface schemes of global or regional climate models.</p>
<p>The releatively recent rise of machine learning (ML) models has been mostly explored for river runoff forecasting, as accurate runoff forecasting, especially over extended periods, is pivotal for effective water resources management <span class="citation" data-cites="fangExaminingApplicabilityDifferent2019 tanAdaptiveMiddleLongterm2018 yangDerivingOperatingRules2018">[@fangExaminingApplicabilityDifferent2019; @tanAdaptiveMiddleLongterm2018; @yangDerivingOperatingRules2018]</span>. Common approaches employ artificial neural networks, support vector machines, adaptive neuro-fuzzy inference systems, and notably, Long Short-Term Memory (LSTM) neural networks that have gained traction for long-term hydrological forecasting due to their excellent performance (Humphrey et al 2016, Huang et al 2014, Ashrafi et al 2017, Yuan et al 2018, Xu et al 2021).</p>
<p>LSTM networks, an evolution of the classical Recurrent Neural Networks (RNNs), have shown stability and efficacy in sequence-to-sequence predictions, such as using climatic indices for rainfall estimation or long-term hydrological forecasting. However, a limitation of LSTMs is their inability to effectively capture two-dimensional structures, an area where Convolutional Neural Networks (CNNs) excel. Reconizing this limitation <span class="citation" data-cites="shi2015">[@shi2015]</span> proposed a convolutional LSTM (ConvLSTM) architectures, which combines the strengths of both LSTM and CNN. The ConvLSTM network has been proven useful for precipitation nowcasting <span class="citation" data-cites="shi2015">[@shi2015]</span> or for river runoff forecasting [<span class="citation" data-cites="ha2021">@ha2021</span>; @niu2020].</p>
<p>In the following we will show that in absence of a fully functioning hydrogolocial model, that also uses a rather complex parametrization, ConvLSTM also represent a robust way to predict multiple rivers at once for any given period using only atmospheric forcing. In this work we use the Baltic Sea catchment to illustrate our approach, while in principal the methodology we propose is universally applicable across various geographic regions. The Baltic Sea serves as a challenging example due to its unique hydrological characteristics, being nearly decoupled from the open ocean (see Figure). As a consequence, the salinity of the Baltic Sea is driven to a large part by freshwater supply from rivers. More generally, the freshwater input into the Baltic Sea comes either as river runoff or a positive net precipitation (precipitation minus evaporation) over the sea surface. The net precipitation accounts for 11 % and the river input for 89 % of the total freshwater input (Meier and Doescher, 2002). Modeling the Baltic Sea is therefore to a large part the result of the quality of the river input, that is used for the simulation. This makes the accurate modeling of river runoff especially critical for simulations pertaining to the Baltic Sea.</p>
<p>In this work we will, we present a ConvLSTM architecture that is able to predict daily river runoff for 97 rivers across the Baltic Sea catchment.</p>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<section id="runoff-data-used-for-training" class="level3">
<h3 class="anchored" data-anchor-id="runoff-data-used-for-training">Runoff data used for training</h3>
</section>
<section id="atmospheric-forcing" class="level3">
<h3 class="anchored" data-anchor-id="atmospheric-forcing">Atmospheric Forcing</h3>
</section>
<section id="lstm-network" class="level3">
<h3 class="anchored" data-anchor-id="lstm-network">LSTM network</h3>
<p>The Long Short-Term Memory (LSTM), a specialized form of Recurrent Neural Networks (RNNs), is specifically tailored for modeling temporal sequences. Its unique design allows it to adeptly handle long-range dependencies, setting it apart from traditional RNNs in terms of accuracy (see <a href="#fig-lstm">Figure&nbsp;1</a>).</p>
<div id="fig-lstm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="draw_lstm.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Inner structure of a Long Short-Term Memory Cell</figcaption><p></p>
</figure>
</div>
<p>This performance in modeling long-range dependencies has been validated in various studies. The key component of LSTM’s innovation is its memory cell, <span class="math inline">\(c_t\)</span>t, which stores state information, also refered to as long-term memory. This cell is accessed, modified, and reset through several self-parameterized gates. For the input of the sequence <span class="math inline">\(x_t\)</span> input, the forget gate <span class="math inline">\(f_t\)</span> defines the percentage of the previous long-term memory status <span class="math inline">\(c_{t-1}\)</span> that should be retained stored​. Next the input gate <span class="math inline">\(i_t\)</span> decides how much of the input is added to the the long-term memory, forming the updated cell state <span class="math inline">\(c_{t}\)</span>. The decision to propagate the latest cell output, <span class="math inline">\(c_t\)</span>, to the final state, <span class="math inline">\(h_t\)</span>, is governed by the output gate, <span class="math inline">\(o_t\)</span>, representing the updated short-term memory of the hidden state <span class="math inline">\(h_t\)</span>. A significant advantage of this architecture is the memory cell’s ability to retain gradients. This mechanism addresses the vanishing gradient problem, where, as input sequences elongate, the influence of initial stages becomes harder to capture, causing gradients of early input points to approach zero. The LSTM’s activation function, inherently recurrent, mirrors the identity function with a consistent derivative of 1.0, ensuring the gradient remains stable throughout backpropagation.</p>
<p>One LSTM cell hence maybe expressed as:</p>
<p><span class="math display">\[
\begin{aligned}
i_t &amp;= \sigma(W_{xi} x_t + W_{hi} h_{t-1} + W_{ci} \circ c_{t-1} + b_i) \\
f_t &amp;= \sigma(W_{xf} x_t + W_{hf} h_{t-1} + W_{cf} \circ c_{t-1} + b_f) \\
c_t &amp;= f_t \circ c_{t-1} + i_t \circ \tanh(W_{xc} x_t + W_{hc} h_{t-1} + b_c) \\
o_t &amp;= \sigma(W_{xo} x_t + W_{ho} h_{t-1} + W_{co} \circ c_t + b_o) \\
h_t &amp;= o_t \circ \tanh(c_t)
\end{aligned}
\]</span></p>
<p>with</p>
<ul>
<li><span class="math inline">\(x_t\)</span>: Input vector at time step <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(h_{t-1}\)</span>: Hidden state from the previous time step.</li>
<li><span class="math inline">\(C_{t-1}\)</span>: Cell state from the previous time step.</li>
<li><span class="math inline">\(W\)</span> and <span class="math inline">\(b\)</span>: Weight matrices and bias vectors, respectively, associated with the gates of the LSTM. The subscripts denote the specific gate or operation they are associated with (e.g., <span class="math inline">\(W_f\)</span> and <span class="math inline">\(b_f\)</span> are the weight matrix and bias for the forget gate).</li>
<li><span class="math inline">\(\sigma\)</span>: Sigmoid activation function (<span class="math inline">\(0,\ldots 1\)</span>)</li>
<li><span class="math inline">\(\tanh\)</span>: Hyperbolic tangent activation function ($ -1 1$)</li>
</ul>
</section>
<section id="convlstm-network" class="level3">
<h3 class="anchored" data-anchor-id="convlstm-network">ConvLSTM network</h3>
<p>The FC-LSTM fails to handle information when handling spatiotemporal data due to its reliance on full connections in both input-to-state and state-to-state transitions. To adress this limitation we use a convLSTM architecture. convLSTM replaces the fully connected operations in the LSTM with convolutional operations. Hence, all inputs <span class="math inline">\(X_1, \ldots, X_t\)</span>, cell outputs <span class="math inline">\(C_1, \ldots, C_t\)</span>, hidden states <span class="math inline">\(H_1, \ldots, H_t\)</span>, and gates <span class="math inline">\(i_t, f_t, o_t\)</span> of the ConvLSTM are 3D tensors. The last two dimensions of these tensors represent spatial dimensions, specifically rows and columns. Conceptually, these inputs and states can be visualized as vectors positioned on a spatial grid.</p>
<p>In the ConvLSTM, the future state of a specific cell on this grid is determined by the inputs and past states of its neighboring cells. This spatial consideration is integrated by employing a convolution operator in both state-to-state and input-to-state transitions, as illustrated in Fig. 2. The foundational equations for ConvLSTM are:</p>
<p><span class="math display">\[
\begin{aligned}
i_t &amp;= \sigma(W_{xi} \ast X_t + W_{hi} \ast H_{t-1} + W_{ci} \circ C_{t-1} + b_i) \\
f_t &amp;= \sigma(W_{xf} \ast X_t + W_{hf} \ast H_{t-1} + W_{cf} \circ C_{t-1} + b_f) \\
C_t &amp;= f_t \circ C_{t-1} + i_t \circ \tanh(W_{xc} \ast X_t + W_{hc} \ast H_{t-1} + b_c) \\
o_t &amp;= \sigma(W_{xo} \ast X_t + W_{ho} \ast H_{t-1} + W_{co} \circ C_t + b_o) \\
H_t &amp;= o_t \circ \tanh(C_t)
\end{aligned}
\]</span></p>
<p>In summary, the ConvLSTM excels at processing tasks that demand a combined understanding of spatial patterns and temporal sequences in data. It merges the image-processing capabilities of Convolutional Neural Networks (CNNs) with the time-series modeling of Long Short-Term Memory (LSTM) networks.</p>
</section>
<section id="implemented-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="implemented-model-architecture">Implemented model architecture</h3>
<p>The ConvLSTM architectures uses and encoder/decoder structure as discussed in TODO. To predict all 97 rivers entering the Baltic Sea, we flatten the output and use fully connected layers to map onto the individual rivers outputs.</p>
<p>An overview of the model structure is given below</p>
<div id="fig-baltNet" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="model_structure.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: BaltConvLSTM</figcaption><p></p>
</figure>
</div>
<p>For the computation we use the following set of hyper parameters:</p>
<div id="tbl-letters" class="anchored">
<table class="table">
<caption>Table&nbsp;1: Hyperparameters</caption>
<thead>
<tr class="header">
<th>Parameter name</th>
<th>Parameter size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Channel size</td>
<td>4</td>
</tr>
<tr class="even">
<td>Num. hidden layer</td>
<td>10</td>
</tr>
<tr class="odd">
<td>Num. timesteps</td>
<td>30</td>
</tr>
<tr class="even">
<td>Conv. Kernelsize</td>
<td>(9,9)</td>
</tr>
<tr class="odd">
<td>Num. ConvLSTM layers</td>
<td>1</td>
</tr>
<tr class="even">
<td>Batch size</td>
<td>64</td>
</tr>
<tr class="odd">
<td>&nbsp;Learning Rate</td>
<td>1e-3 with CosineAnnealing</td>
</tr>
</tbody>
</table>
</div>
<p>As input the model receives 30 days of atmospheric surface fields temperature <span class="math inline">\(T\)</span>, precipitation <span class="math inline">\(P\)</span>, specific humidity <span class="math inline">\(Q\)</span> and wind speed <span class="math inline">\(W\)</span>, with a daily resolution to predict the river runoff <span class="math inline">\(R\)</span> at the time step <span class="math inline">\(\Delta t+1\)</span> , which can be summarized as</p>
<p><span class="math inline">\(R_{\Delta t+1} = f\left(T_{t-30:t}, P_{t-30:t}, Q_{t-30:t}, W_{t-30:t}\right)\)</span></p>
<p>with f being a function maps the 30 days of daily atmospheric surface fields data to the predicted river runoff.</p>
<p>The choice of atmospheric fields was based on the implemented river runoff calculation in the atmospheric model COSMO-CLM which uses these four fields to calculate an river runoff estimate.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>For the evaluation of the model performance we consider the period 1979 to 2011. For this period no bias correction was applied to the orignal E-HYPE dataset. We chose a split of 80% training data, 10% validation data to evaluate the performance of the model during training, and 10% training data that is finally used to evaluate the performance of the model after training.</p>
<p><a href="#fig-PerformanceNeuralNetworkRunoff">Figure&nbsp;3</a> shows the perfomance of the model using the test dataset. The predicted total river runoff for the Baltic Sea is closely matching the original data. Zooming in on the largest individual rivers (lower panels) it can be seen that that also the prediction of the inidivual rivers is close to the original data.</p>
<div id="fig-PerformanceNeuralNetworkRunoff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/paste-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Figure ..</figcaption><p></p>
</figure>
</div>
<p>The accuracy of the model is further displayed in <a href="#fig-statistical-evaluationNN">Figure&nbsp;4</a> . The correlation is close to 1 and the residuals show the error of the model is below 1% of the original data.</p>
<div id="fig-statistical-evaluationNN" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/paste-4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;4: Figure …</figcaption><p></p>
</figure>
</div>
<p>Lastly, we evaluated the performance of the runoff model by incorporating the predicted river runoff as forcing into the ocean model MOM5. This provides a robust validation of the runoff model against more complex real world conditions. This allows us to ensure that the predictions accurately reflect the impact of the river discharge on the ocean dynamics, validating the temporal and spatial variability of the the river discharge. <strong>?@fig-by15</strong> shows the salinity comparison between the original E-HYPE river runoff and the predicted river runoff at BY15 - a central stations in the Baltic Sea.</p>
<p><img src="images/paste-5.png" id="fig-by15" class="img-fluid"></p>
</section>
<section id="acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<p>Phasellus interdum tincidunt ex, a euismod massa pulvinar at. Ut fringilla ut nisi nec volutpat. Morbi imperdiet congue tincidunt. Vivamus eget rutrum purus. Etiam et pretium justo. Donec et egestas sem. Donec molestie ex sit amet viverra egestas. Nullam justo nulla, fringilla at iaculis in, posuere non mauris. Ut eget imperdiet elit.</p>
</section>
<section id="open-research" class="level2">
<h2 class="anchored" data-anchor-id="open-research">Open research</h2>
<p>Phasellus interdum tincidunt ex, a euismod massa pulvinar at. Ut fringilla ut nisi nec volutpat. Morbi imperdiet congue tincidunt. Vivamus eget rutrum purus. Etiam et pretium justo. Donec et egestas sem. Donec molestie ex sit amet viverra egestas. Nullam justo nulla, fringilla at iaculis in, posuere non mauris. Ut eget imperdiet elit.</p>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<div id="refs" role="doc-bibliography">

</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>