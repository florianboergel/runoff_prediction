[
  {
    "objectID": "03_shared_utilities.html",
    "href": "03_shared_utilities.html",
    "title": "BalticRiverPrediction",
    "section": "",
    "text": "datapath = \"/silor/boergel/paper/runoff_prediction/data\"\nlabels = xr.open_dataset(f\"{datapath}/runoffData/combined_fastriver_008.nc\")\n\n\n\npreprocess\n\n preprocess (ds)\n\n\n\n\nread_netcdfs\n\n read_netcdfs (files, dim, transform_func, transform_calendar=None,\n               cftime=True)\n\nReads multiples netcdfs files\n\n\n\ntransform_calendar\n\n transform_calendar (ds, timedim='time',\n                     calendarname='proleptic_gregorin')\n\nTransforms calendar of time index in xarray dataset\n\n\n\nplot_loss_and_acc\n\n plot_loss_and_acc (log_dir, loss_ylim=(0.0, 0.9), acc_ylim=(0.7, 1.0),\n                    save_loss=None, save_acc=None)"
  },
  {
    "objectID": "02_BaltNet.html",
    "href": "02_BaltNet.html",
    "title": "BalticRiverPrediction",
    "section": "",
    "text": "BaltNet\n\n BaltNet (modelPar)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nBaseLineModel\n\n BaseLineModel (modelPar)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nLightningModel\n\n LightningModel (model, learning_rate, cosine_t_max)\n\nHooks to be used in LightningModule.\n\n\n\nAtmosphericDataset\n\n AtmosphericDataset (datapath, transform=None)\n\nAn abstract class representing a :class:Dataset.\nAll datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite :meth:__getitem__, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite :meth:__len__, which is expected to return the size of the dataset by many :class:~torch.utils.data.Sampler implementations and the default options of :class:~torch.utils.data.DataLoader.\n.. note:: :class:~torch.utils.data.DataLoader by default constructs a index sampler that yields integral indices. To make it work with a map-style dataset with non-integral indices/keys, a custom sampler must be provided.\n\n\n\nAtmosphereDataModule\n\n AtmosphereDataModule (datapath, batch_size=64, num_workers=8,\n                       add_first_dim=True)\n\nA DataModule standardizes the training, val, test splits, data preparation and transforms. The main advantage is consistent data splits, data preparation and transforms across models.\nExample::\nclass MyDataModule(LightningDataModule):\n    def __init__(self):\n        super().__init__()\n    def prepare_data(self):\n        # download, split, etc...\n        # only called on 1 GPU/TPU in distributed\n    def setup(self, stage):\n        # make assignments here (val/train/test split)\n        # called on every process in DDP\n    def train_dataloader(self):\n        train_split = Dataset(...)\n        return DataLoader(train_split)\n    def val_dataloader(self):\n        val_split = Dataset(...)\n        return DataLoader(val_split)\n    def test_dataloader(self):\n        test_split = Dataset(...)\n        return DataLoader(test_split)\n    def teardown(self):\n        # clean up after fit or test\n        # called on every process in DDP\n\n# Our GPU has tensor cores, hence mixed precision training is enabled\n# see https://sebastianraschka.com/blog/2023/llm-mixed-precision-copy.html\n# for more\n\ntorch.set_float32_matmul_precision(\"medium\")\n\n\nL.pytorch.seed_everything(123)\n\nGlobal seed set to 123\n\n\n123\n\n\nQuickly inspect if \\(\\Delta t\\) in the data changes. If not simply resampling should do it.\n\ndatapath = \"/silor/boergel/paper/runoff_prediction/data\"\nlabels = xr.open_mfdataset(f\"{datapath}/runoffData/combined_fastriver_00*.nc\", combine=\"nested\", concat_dim=\"river\")\nlabels.time.diff(\"time\").diff(\"time\").plot()\n\n\n\n\n\n# runoff = read_netcdfs(\n#     f\"{datapath}/runoffData/combined_fastriver_*.nc\",\n#     dim=\"river\",\n#     transform_func = lambda ds:ds.roflux.resample(time=\"1D\").mean(),\n#     cftime=False\n\n\n# runoff = runoff.transpose(\"time\", \"river\")\n\n\ndataLoader = AtmosphereDataModule(\n    datapath=\"/silor/boergel/paper/runoff_prediction/data\",\n    batch_size=64\n    )\n\n\nmodelParameters = {\n    \"input_dim\":30, # timesteps\n    \"hidden_dim\":1, # Channels -> right now only precipitation\n    \"kernel_size\":(3,3), # applied for spatial convolutions\n    \"num_layers\":2, # number of convLSTM layers\n    \"batch_first\":True, # first index is batch\n    \"bias\":True, \n    \"return_all_layers\": False, \n    \"dimensions\": (191, 206) # dimensions of atmospheric forcing\n}\n\nnum_epochs = 50\n\n\npyTorchBaltNet = BaltNet(modelPar=modelParameters)\nLighningBaltNet = LightningModel(pyTorchBaltNet, learning_rate=1e-3, cosine_t_max=num_epochs)\n\n\ncallbacks = [\n    ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"val_mse\", save_last=True)\n]\n\n\ntrainer = L.Trainer(\n    max_epochs=num_epochs,\n    accelerator=\"cuda\",\n    devices=2,\n    logger=CSVLogger(save_dir=\"/silor/boergel/paper/runoff_prediction/logs\", name=\"BaltNet1\"),\n    deterministic=True,\n)\n\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n\n\ntrainer.fit(model=LighningBaltNet, datamodule=dataLoader)\n\n[rank: 0] Global seed set to 123\n[rank: 1] Global seed set to 123\nInitializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nInitializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n100%|██████████| 54/54 [01:14<00:00,  1.37s/it]\n100%|██████████| 54/54 [02:02<00:00,  2.26s/it]\n100%|██████████| 97/97 [08:00<00:00,  4.96s/it]\n100%|██████████| 97/97 [08:08<00:00,  5.03s/it]\nLOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n\n  | Name      | Type             | Params\n-----------------------------------------------\n0 | model     | BaltNet          | 20.3 M\n1 | train_mse | MeanSquaredError | 0     \n2 | val_mse   | MeanSquaredError | 0     \n3 | test_mse  | MeanSquaredError | 0     \n-----------------------------------------------\n20.3 M    Trainable params\n0         Non-trainable params\n20.3 M    Total params\n81.217    Total estimated model params size (MB)\n\n\nEpoch 49: 100%|██████████| 123/123 [00:20<00:00,  5.94it/s, v_num=46, train_mse_step=0.00623, train_loss_step=0.00623, val_mse=0.0138, train_mse_epoch=0.00652, train_loss_epoch=0.00652]\n\n\n`Trainer.fit` stopped: `max_epochs=50` reached.\n\n\nEpoch 49: 100%|██████████| 123/123 [00:21<00:00,  5.72it/s, v_num=46, train_mse_step=0.00623, train_loss_step=0.00623, val_mse=0.0138, train_mse_epoch=0.00652, train_loss_epoch=0.00652]\n\n\n\ntrainer.test(model=LighningBaltNet, datamodule=dataLoader)\n\n[rank: 1] Global seed set to 123\n[rank: 0] Global seed set to 123\nInitializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\nInitializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n\n\n----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n100%|██████████| 54/54 [01:05<00:00,  1.22s/it]\n100%|██████████| 54/54 [02:01<00:00,  2.60s/it]\n100%|██████████| 97/97 [08:05<00:00,  5.01s/it]\n100%|██████████| 97/97 [08:10<00:00,  5.06s/it]\nLOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:226: PossibleUserWarning: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n  rank_zero_warn(\n\n\nTesting DataLoader 0: 100%|██████████| 15/15 [00:03<00:00,  4.00it/s]\n\n\n/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n  warning_cache.warn(\n\n\nTesting DataLoader 0: 100%|██████████| 15/15 [00:03<00:00,  3.99it/s]\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃   Runningstage.testing    ┃                           ┃\n┃          metric           ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         test_loss         │   0.013884569518268108    │\n│         test_mse          │   0.014290162362158298    │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n[{'test_loss': 0.013884569518268108, 'test_mse': 0.014290162362158298}]"
  },
  {
    "objectID": "convLSTM.html",
    "href": "convLSTM.html",
    "title": "Convolutional Long-Shortterm Memory Network (ConvLSTM)",
    "section": "",
    "text": "This code represent an implementation of the model structure suggested by Shi et al. (2015) - Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. The idea is by extending the fully connected LSTM (FC-LSTM) with convolutional strucutres in both the input-to-state and state-to-state transitions (input and hidden state) which is named convolutional LSTM (convLSTM)."
  },
  {
    "objectID": "convLSTM.html#the-model",
    "href": "convLSTM.html#the-model",
    "title": "Convolutional Long-Shortterm Memory Network (ConvLSTM)",
    "section": "The model",
    "text": "The model\nAlthough the FC-LSTM has proven powerpful for handling temporal correlations, it contains to much redundancy for spatial data. To adresse that the author propose to include convolutional strucutres. By stacking multiple ConvLSTM layers they were able to predit spatiotemporal sequences. The major drawback of FC-LSTM in handling spatiotemporal data is its usage of full connections in input to state and state-to-state transitions in which no spatial informations is encoded\nThe ConvLSTM determines the future state of a certain cell in the grid by the inputs and past states of its local neighbors. This can easily be achieved by using a convolution operator in the state-to-state and input-to-state transitions.\nHere are the key equations where * denotes the convolutional operator and \\(\\circ\\) as before the Hadamard product:\n\\[\ni_t = \\sigma(W_{xi}*X_t+W_{hi}*H_{t-1}+W_{ci}\\circ C_{t-1}+bi) \\\\\nf_t = \\sigma(W_{xf}*X_t+W_{hf}*H_{t-1}+W_{cf}\\circ C_{t-1}+bf) \\\\\nC_t = f_t \\circ C_{t-1} + i_t \\circ tanh(W_{xc}*X_t+W_{hc}* H_{t-1}+bc) \\\\\no_t = \\sigma(W_{xo}*X_t+W_{ho}*H_{t-1}+W_{co}\\circ C_{t-1}+bo) \\\\\nH_t = o_t \\circ tanh (C_t)\n\\]\n\n\n\nConvLSTMCell\n\n ConvLSTMCell (input_dim, hidden_dim, kernel_size, bias)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nConvLSTM\n\n ConvLSTM (input_dim, hidden_dim, kernel_size, num_layers,\n           batch_first=False, bias=True, return_all_layers=False)\n\nParameters: input_dim: Number of channels in input hidden_dim: Number of hidden channels kernel_size: Size of kernel in convolutions num_layers: Number of LSTM layers stacked on each other batch_first: Whether or not dimension 0 is the batch or not bias: Bias or no bias in Convolution return_all_layers: Return the list of computations for all layers Note: Will do same padding.\nInput: A tensor of size B, T, C, H, W or T, B, C, H, W Output: A tuple of two lists of length num_layers (or length 1 if return_all_layers is False). 0 - layer_output_list is the list of lists of length T of each output 1 - last_state_list is the list of last states each element of the list is a tuple (h, c) for hidden state and memory Example: >> x = torch.rand((32, 10, 64, 128, 128)) >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False) >> _, last_states = convlstm(x) >> h = last_states[0][0] # 0 for layer index, 0 for h index"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Baltic River Prediction",
    "section": "",
    "text": "The file mask.nc contains masks for each catchment area belonging to a particular basin. Each basin is identified with a mask values. This file can be used as a basis to train a neural network to map atmospheric variables onto a rivers that supply the individual basins."
  },
  {
    "objectID": "index.html#river-locations",
    "href": "index.html#river-locations",
    "title": "Baltic River Prediction",
    "section": "River locations",
    "text": "River locations\nThe file rivers.json contains a list of river mouths and their locations in longitudes and latitudes."
  },
  {
    "objectID": "index.html#grid-file",
    "href": "index.html#grid-file",
    "title": "Baltic River Prediction",
    "section": "Grid file",
    "text": "Grid file\nThe file t_grid.nc specifies the grid on which the runoff model will work. This model is curently named ROFF. The file is in the SCRIP format and contains the region that is masked in mask.nc. However, the grid is transformed to a grid with rank one, i.e. all grid points are aligned in a one-dimensional array."
  },
  {
    "objectID": "index.html#river-locations-on-the-model-grids",
    "href": "index.html#river-locations-on-the-model-grids",
    "title": "Baltic River Prediction",
    "section": "River locations on the model grids",
    "text": "River locations on the model grids\nThe file model_points.json contains a list of all rivers in rivers.json with their location mapped on the involved model grid points, i.e. nearest neighboring points of the true locations."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Baltic River Prediction",
    "section": "Installation",
    "text": "Installation"
  }
]