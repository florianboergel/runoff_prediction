{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp BaltNet\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaltNet\n",
    "\n",
    "Model architecture used for predicting river runoff in the Baltic Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from BalticRiverPrediction.convLSTM import ConvLSTM\n",
    "from BalticRiverPrediction.sharedUtilities import read_netcdfs, preprocess, plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/silor/boergel/paper/runoff_prediction/nbs/02_BaltNet.ipynb Zelle 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bphy4/silor/boergel/paper/runoff_prediction/nbs/02_BaltNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#| export\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bphy4/silor/boergel/paper/runoff_prediction/nbs/02_BaltNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBaltNet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bphy4/silor/boergel/paper/runoff_prediction/nbs/02_BaltNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, modelPar):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bphy4/silor/boergel/paper/runoff_prediction/nbs/02_BaltNet.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39msuper\u001b[39m(BaltNet, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class BaltNet(nn.Module):\n",
    "    def __init__(self, modelPar):\n",
    "        super(BaltNet, self).__init__()\n",
    "\n",
    "        # Initialize all attributes\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.encoder = ConvLSTM(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=self.batch_first,\n",
    "            bias=self.bias,\n",
    "            return_all_layers=False\n",
    "        )\n",
    "\n",
    "        self.decoder = ConvLSTM(\n",
    "            input_dim=self.hidden_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            num_layers=1,\n",
    "            batch_first=self.batch_first,\n",
    "            bias=self.bias,\n",
    "            return_all_layers=False\n",
    "        )\n",
    "\n",
    "        self.linear_dim = self.dimensions[0] * self.dimensions[1] * self.hidden_dim \n",
    "\n",
    "        # Single fully connected network for all rivers\n",
    "         \n",
    "        self.river_predictors = nn.Sequential(\n",
    "            nn.Linear(self.linear_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 97)\n",
    "        )\n",
    "\n",
    "        # Creating separate attention weights for each river\n",
    "        self.attention_weights = nn.Parameter(torch.randn(self.hidden_dim, 1, 1), requires_grad=True)  # 97 rivers\n",
    "\n",
    "    def spatial_attention(self, x):\n",
    "        \"\"\"Spatial attention mechanism.\"\"\"\n",
    "        B, T, C, H, W = x.size()\n",
    "\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        \n",
    "        # Apply attention weights for all rivers\n",
    "        self.attention_map = torch.sigmoid(F.conv2d(x, self.attention_weights.unsqueeze(0), bias=None, stride=1, padding=0))\n",
    "        \n",
    "        # Weighted sum\n",
    "        output = x * self.attention_map  # B*T, C, H, W\n",
    "        output = output.view(B, T, C, H, W)  # B, T, C\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, _, _, _, _ = x.size()\n",
    "\n",
    "        # Pass through encoder\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x)\n",
    "\n",
    "        # Use the entire encoder output as input to the decoder\n",
    "        decoder_input = encoder_outputs[0][:,-1,:,:,:].unsqueeze(1)\n",
    "\n",
    "        # Pass through decoder using the final hidden state of the encoder\n",
    "        decoder_outputs, _ = self.decoder(decoder_input, encoder_hidden)\n",
    "\n",
    "        # Apply spatial attention\n",
    "        decoder_with_spatial_attention = self.spatial_attention(decoder_outputs[0])  # B, T, C, H, W\n",
    "            \n",
    "        # Flatten the temporal sequence\n",
    "        decoder_with_spatial_attention_flattened = decoder_with_spatial_attention.view(B, -1)  #\n",
    "            \n",
    "        # Pass through its own predictor\n",
    "        output = self.river_predictors(decoder_with_spatial_attention_flattened)  # B, -1\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet\n",
       "\n",
       ">      BaltNet (modelPar)\n",
       "\n",
       "A custom neural network architecture designed for sequence-to-sequence learning using convolutional LSTMs.\n",
       "\n",
       "Attributes:\n",
       "- encoder: A convolutional LSTM serving as the encoder.\n",
       "- decoder: A convolutional LSTM serving as the decoder.\n",
       "- river_predictors: A feed-forward network for predicting river values.\n",
       "- attention_weights: Weights for the spatial attention mechanism.\n",
       "\n",
       "Parameters:\n",
       "- modelPar (dict): Dictionary containing the model parameters."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet\n",
       "\n",
       ">      BaltNet (modelPar)\n",
       "\n",
       "A custom neural network architecture designed for sequence-to-sequence learning using convolutional LSTMs.\n",
       "\n",
       "Attributes:\n",
       "- encoder: A convolutional LSTM serving as the encoder.\n",
       "- decoder: A convolutional LSTM serving as the decoder.\n",
       "- river_predictors: A feed-forward network for predicting river values.\n",
       "- attention_weights: Weights for the spatial attention mechanism.\n",
       "\n",
       "Parameters:\n",
       "- modelPar (dict): Dictionary containing the model parameters."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet.spatial_attention\n",
       "\n",
       ">      BaltNet.spatial_attention (x)\n",
       "\n",
       "Applies the spatial attention mechanism to the input tensor.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Input tensor after applying the spatial attention mechanism."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet.spatial_attention\n",
       "\n",
       ">      BaltNet.spatial_attention (x)\n",
       "\n",
       "Applies the spatial attention mechanism to the input tensor.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Input tensor after applying the spatial attention mechanism."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet.spatial_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet.forward\n",
       "\n",
       ">      BaltNet.forward (x)\n",
       "\n",
       "Forward pass of the BaltNet.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Predicted values for the rivers."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet.forward\n",
       "\n",
       ">      BaltNet.forward (x)\n",
       "\n",
       "Forward pass of the BaltNet.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Predicted values for the rivers."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LightningModel(L.LightningModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning model for training and evaluation.\n",
    "    \n",
    "    Attributes:\n",
    "        model (nn.Module): The neural network model.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
    "        train_mse (torchmetrics.MeanSquaredError): Metric for training mean squared error.\n",
    "        val_mse (torchmetrics.MeanSquaredError): Metric for validation mean squared error.\n",
    "        test_mse (torchmetrics.MeanSquaredError): Metric for testing mean squared error.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, learning_rate, cosine_t_max):\n",
    "        \"\"\"\n",
    "        Initializes the LightningModel.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The neural network model.\n",
    "            learning_rate (float): Learning rate for the optimizer.\n",
    "            cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.cosine_t_max = cosine_t_max\n",
    "\n",
    "        # Save hyperparameters except the model\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        # Define metrics\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.val_mse = torchmetrics.MeanSquaredError()\n",
    "        self.test_mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the model.\"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _shared_step(self, batch, debug=False):\n",
    "        \"\"\"\n",
    "        Shared step for training, validation, and testing.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Input batch of data.\n",
    "            debug (bool, optional): If True, prints the loss. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Computed loss, true labels, and predicted labels.\n",
    "        \"\"\"\n",
    "        features, true_labels = batch\n",
    "        logits = self.model(features)\n",
    "        loss = F.mse_loss(logits, true_labels)\n",
    "        if debug:\n",
    "            print(loss)\n",
    "        return loss, true_labels, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.train_mse(predicted_labels, true_labels)\n",
    "        metrics = {\"train_mse\": mse, \"train_loss\": loss}\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Validation step.\"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.val_mse(predicted_labels, true_labels)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True, sync_dist=True)\n",
    "    \n",
    "    def test_step(self, batch, _):\n",
    "        \"\"\"Test step.\"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.test_mse(predicted_labels, true_labels)\n",
    "        self.log(\"test_loss\", loss, rank_zero_only=True)\n",
    "        self.log(\"test_mse\", mse, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        _, _, predicted_labels = self._shared_step(batch)\n",
    "        return predicted_labels\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler.\n",
    "\n",
    "        Returns:\n",
    "            tuple: List of optimizers and list of learning rate schedulers.\n",
    "        \"\"\"\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n",
    "        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10, verbose=False)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": sch, \"monitor\": \"val_mse\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningModel\n",
       "\n",
       ">      LightningModel (model, learning_rate, cosine_t_max)\n",
       "\n",
       "A custom PyTorch Lightning model designed for the encapsulation of training, validation, and testing logic of a neural network.\n",
       "\n",
       "Attributes:\n",
       "- model (nn.Module): The main neural network.\n",
       "- learning_rate (float): Learning rate used for optimization.\n",
       "- cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
       "- train_mse, val_mse, test_mse (torchmetrics.MeanSquaredError): Metrics for computing the mean squared error during training, validation, and testing respectively."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningModel\n",
       "\n",
       ">      LightningModel (model, learning_rate, cosine_t_max)\n",
       "\n",
       "A custom PyTorch Lightning model designed for the encapsulation of training, validation, and testing logic of a neural network.\n",
       "\n",
       "Attributes:\n",
       "- model (nn.Module): The main neural network.\n",
       "- learning_rate (float): Learning rate used for optimization.\n",
       "- cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
       "- train_mse, val_mse, test_mse (torchmetrics.MeanSquaredError): Metrics for computing the mean squared error during training, validation, and testing respectively."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningModel._shared_step\n",
       "\n",
       ">      LightningModel._shared_step (batch, debug=False)\n",
       "\n",
       "A shared method for computation during training, validation, and testing.\n",
       "\n",
       "Args:\n",
       "    batch (tuple): Input data batch.\n",
       "    debug (bool, optional): If set to True, the method will print the loss value. Defaults to False.\n",
       "\n",
       "Returns:\n",
       "    tuple: Computed loss, actual labels, and predicted labels."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningModel._shared_step\n",
       "\n",
       ">      LightningModel._shared_step (batch, debug=False)\n",
       "\n",
       "A shared method for computation during training, validation, and testing.\n",
       "\n",
       "Args:\n",
       "    batch (tuple): Input data batch.\n",
       "    debug (bool, optional): If set to True, the method will print the loss value. Defaults to False.\n",
       "\n",
       "Returns:\n",
       "    tuple: Computed loss, actual labels, and predicted labels."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningModel._shared_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphericDataset(Dataset):\n",
    "    def __init__(self, input_size, atmosphericData, runoff, transform=None):\n",
    "\n",
    "        # Length of the sequence\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # input data (x) \n",
    "        atmosphericDataStd = atmosphericData.std(\"time\") # dimension will be channel, lat, lon\n",
    "        atmosphericDataMean = atmosphericData.mean(\"time\")\n",
    "        self.atmosphericStats = (atmosphericDataMean, atmosphericDataStd)\n",
    "\n",
    "        # output data - label (y)\n",
    "        runoffData = runoff.transpose(\"time\", \"river\")\n",
    "        runoffDataMean = runoffData.mean(\"time\")\n",
    "        runoffDataSTD = runoffData.std(\"time\")\n",
    "        self.runoffDataStats = (runoffDataMean, runoffDataSTD)\n",
    "        \n",
    "        # normalize data\n",
    "        X = ((atmosphericData - atmosphericDataMean)/atmosphericDataStd).compute()\n",
    "        y = ((runoffData - runoffDataMean)/runoffDataSTD).compute()\n",
    "        \n",
    "        # an additional dimension for the channel is added\n",
    "        # to end up with (time, channel, lat, lon)\n",
    "        xStacked = X.to_array(dim='variable')\n",
    "        xStacked = xStacked.transpose(\"time\", \"variable\", \"y\", \"x\")\n",
    "\n",
    "        assert xStacked.data.ndim == 4\n",
    "        self.x = torch.tensor(xStacked.data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.data, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index:index+(self.input_size)], self.y[index+int(self.input_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]-(self.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AtmosphericDataset\n",
       "\n",
       ">      AtmosphericDataset (input_size, atmosphericData, runoff, transform=None)\n",
       "\n",
       "Dataset for atmospheric data and runoff prediction.\n",
       "\n",
       "Attributes:\n",
       "- input_size (int): Length of the input sequence.\n",
       "- atmosphericStats (tuple): Mean and standard deviation of the atmospheric data along the time dimension.\n",
       "- runoffDataStats (tuple): Mean and standard deviation of the runoff data along the time dimension.\n",
       "- x (torch.Tensor): Normalized atmospheric data tensor with dimensions (time, channel, lat, lon).\n",
       "- y (torch.Tensor): Normalized runoff data tensor with dimensions (time, river)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AtmosphericDataset\n",
       "\n",
       ">      AtmosphericDataset (input_size, atmosphericData, runoff, transform=None)\n",
       "\n",
       "Dataset for atmospheric data and runoff prediction.\n",
       "\n",
       "Attributes:\n",
       "- input_size (int): Length of the input sequence.\n",
       "- atmosphericStats (tuple): Mean and standard deviation of the atmospheric data along the time dimension.\n",
       "- runoffDataStats (tuple): Mean and standard deviation of the runoff data along the time dimension.\n",
       "- x (torch.Tensor): Normalized atmospheric data tensor with dimensions (time, channel, lat, lon).\n",
       "- y (torch.Tensor): Normalized runoff data tensor with dimensions (time, river)."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AtmosphericDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AtmosphereDataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, atmosphericData, runoff, batch_size=64, num_workers=8, add_first_dim=True, input_size=30):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = atmosphericData\n",
    "        self.runoff = runoff\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.add_first_dim = add_first_dim\n",
    "        self.input_size = input_size\n",
    "    \n",
    "    def setup(self, stage:str):\n",
    "        UserWarning(\"Loading atmospheric data ...\")\n",
    "        dataset = AtmosphericDataset(\n",
    "            atmosphericData=self.data,\n",
    "            runoff=self.runoff,\n",
    "            input_size=self.input_size\n",
    "            )\n",
    "        n_samples = len(dataset)\n",
    "        train_size = int(0.85 * n_samples)\n",
    "        val_size = n_samples - train_size\n",
    "        # self.train, self.val = train_test_split(dataset)\n",
    "        self.train, self.val, = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True, \n",
    "            drop_last=True, \n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False  # Speed up data transfer to GPU\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "            pin_memory=False  # Speed up data transfer to GPU\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AtmosphereDataModule\n",
       "\n",
       ">      AtmosphereDataModule (atmosphericData, runoff, batch_size=64,\n",
       ">                            num_workers=8, add_first_dim=True, input_size=30)\n",
       "\n",
       "A PyTorch Lightning DataModule for preparing and loading atmospheric and runoff datasets.\n",
       "\n",
       "Attributes:\n",
       "    data (xr.DataArray): The atmospheric data.\n",
       "    runoff (xr.DataArray): The runoff data corresponding to the atmospheric data.\n",
       "    batch_size (int): The batch size for the DataLoader.\n",
       "    num_workers (int): Number of subprocesses to use for data loading.\n",
       "    add_first_dim (bool): Flag to determine if a first dimension needs to be added. (Not used in current implementation).\n",
       "    input_size (int): The input sequence length for the `AtmosphericDataset`.\n",
       "    train (Dataset): Training dataset.\n",
       "    val (Dataset): Validation dataset."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AtmosphereDataModule\n",
       "\n",
       ">      AtmosphereDataModule (atmosphericData, runoff, batch_size=64,\n",
       ">                            num_workers=8, add_first_dim=True, input_size=30)\n",
       "\n",
       "A PyTorch Lightning DataModule for preparing and loading atmospheric and runoff datasets.\n",
       "\n",
       "Attributes:\n",
       "    data (xr.DataArray): The atmospheric data.\n",
       "    runoff (xr.DataArray): The runoff data corresponding to the atmospheric data.\n",
       "    batch_size (int): The batch size for the DataLoader.\n",
       "    num_workers (int): Number of subprocesses to use for data loading.\n",
       "    add_first_dim (bool): Flag to determine if a first dimension needs to be added. (Not used in current implementation).\n",
       "    input_size (int): The input sequence length for the `AtmosphericDataset`.\n",
       "    train (Dataset): Training dataset.\n",
       "    val (Dataset): Validation dataset."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AtmosphereDataModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
