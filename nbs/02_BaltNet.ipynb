{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp BaltNet\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaltNet\n",
    "\n",
    "Model architecture used for predicting river runoff in the Baltic Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from BalticRiverPrediction.convLSTM import ConvLSTM\n",
    "from BalticRiverPrediction.sharedUtilities import read_netcdfs, preprocess, plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaltNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A custom neural network architecture designed for sequence-to-sequence learning using convolutional LSTMs.\n",
    "    \n",
    "    Attributes:\n",
    "    - encoder: A convolutional LSTM serving as the encoder.\n",
    "    - decoder: A convolutional LSTM serving as the decoder.\n",
    "    - river_predictors: A feed-forward network for predicting river values.\n",
    "    - attention_weights: Weights for the spatial attention mechanism.\n",
    "    \n",
    "    Parameters:\n",
    "    - modelPar (dict): Dictionary containing the model parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, modelPar):\n",
    "        super(BaltNet, self).__init__()\n",
    "\n",
    "        # Initialize model parameters from the provided dictionary\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        # Initialize encoder using convolutional LSTM\n",
    "        self.encoder = ConvLSTM(\n",
    "            input_dim=self.input_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=self.batch_first,\n",
    "            bias=self.bias,\n",
    "            return_all_layers=False\n",
    "        )\n",
    "\n",
    "        # Initialize decoder using convolutional LSTM\n",
    "        self.decoder = ConvLSTM(\n",
    "            input_dim=self.hidden_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            num_layers=1,\n",
    "            batch_first=self.batch_first,\n",
    "            bias=self.bias,\n",
    "            return_all_layers=False\n",
    "        )\n",
    "\n",
    "        # Compute the linear dimension for the feed-forward network\n",
    "        self.linear_dim = self.dimensions[0] * self.dimensions[1] * self.hidden_dim \n",
    "\n",
    "        # Define the feed-forward network for river predictions\n",
    "        self.river_predictors = nn.Sequential(\n",
    "            nn.Linear(self.linear_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 97)\n",
    "        )\n",
    "\n",
    "        # Initialize attention weights for spatial attention mechanism\n",
    "        self.attention_weights = nn.Parameter(torch.randn(self.hidden_dim, 1, 1), requires_grad=True)\n",
    "\n",
    "    def spatial_attention(self, x):\n",
    "        \"\"\"\n",
    "        Applies the spatial attention mechanism to the input tensor.\n",
    "        \n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
    "        \n",
    "        Returns:\n",
    "        - output (torch.Tensor): Input tensor after applying the spatial attention mechanism.\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = x.size()\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        # Apply attention weights\n",
    "        self.attention_map = torch.sigmoid(F.conv2d(x, self.attention_weights.unsqueeze(0), bias=None, stride=1, padding=0))\n",
    "        # Obtain weighted sum\n",
    "        output = x * self.attention_map\n",
    "        output = output.view(B, T, C, H, W)\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the BaltNet.\n",
    "        \n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
    "        \n",
    "        Returns:\n",
    "        - output (torch.Tensor): Predicted values for the rivers.\n",
    "        \"\"\"\n",
    "        B, _, _, _, _ = x.size()\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x)\n",
    "        decoder_input = encoder_outputs[0][:,-1,:,:,:].unsqueeze(1)\n",
    "        decoder_outputs, _ = self.decoder(decoder_input, encoder_hidden)\n",
    "        decoder_with_spatial_attention = self.spatial_attention(decoder_outputs[0])\n",
    "        decoder_with_spatial_attention_flattened = decoder_with_spatial_attention.view(B, -1)\n",
    "        output = self.river_predictors(decoder_with_spatial_attention_flattened)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet\n",
       "\n",
       ">      BaltNet (modelPar)\n",
       "\n",
       "A custom neural network architecture designed for sequence-to-sequence learning using convolutional LSTMs.\n",
       "\n",
       "Attributes:\n",
       "- encoder: A convolutional LSTM serving as the encoder.\n",
       "- decoder: A convolutional LSTM serving as the decoder.\n",
       "- river_predictors: A feed-forward network for predicting river values.\n",
       "- attention_weights: Weights for the spatial attention mechanism.\n",
       "\n",
       "Parameters:\n",
       "- modelPar (dict): Dictionary containing the model parameters."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet\n",
       "\n",
       ">      BaltNet (modelPar)\n",
       "\n",
       "A custom neural network architecture designed for sequence-to-sequence learning using convolutional LSTMs.\n",
       "\n",
       "Attributes:\n",
       "- encoder: A convolutional LSTM serving as the encoder.\n",
       "- decoder: A convolutional LSTM serving as the decoder.\n",
       "- river_predictors: A feed-forward network for predicting river values.\n",
       "- attention_weights: Weights for the spatial attention mechanism.\n",
       "\n",
       "Parameters:\n",
       "- modelPar (dict): Dictionary containing the model parameters."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet.spatial_attention\n",
       "\n",
       ">      BaltNet.spatial_attention (x)\n",
       "\n",
       "Applies the spatial attention mechanism to the input tensor.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Input tensor after applying the spatial attention mechanism."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet.spatial_attention\n",
       "\n",
       ">      BaltNet.spatial_attention (x)\n",
       "\n",
       "Applies the spatial attention mechanism to the input tensor.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Input tensor after applying the spatial attention mechanism."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet.spatial_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BaltNet.forward\n",
       "\n",
       ">      BaltNet.forward (x)\n",
       "\n",
       "Forward pass of the BaltNet.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Predicted values for the rivers."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BaltNet.forward\n",
       "\n",
       ">      BaltNet.forward (x)\n",
       "\n",
       "Forward pass of the BaltNet.\n",
       "\n",
       "Parameters:\n",
       "- x (torch.Tensor): Input tensor of shape `(batch_size, sequence_length, channels, height, width)`.\n",
       "\n",
       "Returns:\n",
       "- output (torch.Tensor): Predicted values for the rivers."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaltNet.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LightningModel(L.LightningModule):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Lightning model designed for the encapsulation of training, validation, and testing logic of a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "    - model (nn.Module): The main neural network.\n",
    "    - learning_rate (float): Learning rate used for optimization.\n",
    "    - train_mse, val_mse, test_mse (torchmetrics.MeanSquaredError): Metrics for computing the mean squared error during training, validation, and testing respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, learning_rate, cosine_t_max):\n",
    "        \"\"\"\n",
    "        Constructor for the LightningModel class.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The primary neural network model.\n",
    "            learning_rate (float): Learning rate for optimization.\n",
    "            cosine_t_max (int): Maximum iterations for the cosine annealing scheduler.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        # Metrics\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.val_mse = torchmetrics.MeanSquaredError()\n",
    "        self.test_mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass computation.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after the forward pass.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_step(self, batch, debug=False):\n",
    "        \"\"\"\n",
    "        A shared method for computation during training, validation, and testing.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Input data batch.\n",
    "            debug (bool, optional): If set to True, the method will print the loss value. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Computed loss, actual labels, and predicted labels.\n",
    "        \"\"\"\n",
    "        features, true_labels = batch\n",
    "        logits = self.model(features)\n",
    "        loss = F.mse_loss(logits, true_labels)\n",
    "        if debug:\n",
    "            print(loss)\n",
    "        return loss, true_labels, logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Logic for one training step.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Training data batch.\n",
    "            batch_idx (int): Index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss value.\n",
    "        \"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.train_mse(predicted_labels, true_labels)\n",
    "        metrics = {\"train_mse\": mse, \"train_loss\": loss}\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Logic for one validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Validation data batch.\n",
    "            batch_idx (int): Index of the batch.\n",
    "        \"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.val_mse(predicted_labels, true_labels)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True, sync_dist=True)\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        \"\"\"\n",
    "        Logic for one testing step.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Testing data batch.\n",
    "            _ : Placeholder for batch index, not used in this method.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Loss value.\n",
    "        \"\"\"\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.test_mse(predicted_labels, true_labels)\n",
    "        self.log(\"test_loss\", loss, rank_zero_only=True)\n",
    "        self.log(\"test_mse\", mse, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
    "        \"\"\"\n",
    "        Logic for one prediction step.\n",
    "\n",
    "        Args:\n",
    "            batch (tuple): Input data batch for prediction.\n",
    "            batch_idx (int): Index of the batch.\n",
    "            dataloader_idx (int, optional): Index of the dataloader. Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted labels.\n",
    "        \"\"\"\n",
    "        _, _, predicted_labels = self._shared_step(batch)\n",
    "        return predicted_labels\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configuration method for optimizers and learning rate schedulers.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing optimizer, learning rate scheduler, and the metric to monitor.\n",
    "        \"\"\"\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
    "        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10, verbose=False)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": sch, \"monitor\": \"val_mse\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningModel\n",
       "\n",
       ">      LightningModel (model, learning_rate, cosine_t_max)\n",
       "\n",
       "A custom PyTorch Lightning model designed for the encapsulation of training, validation, and testing logic of a neural network.\n",
       "\n",
       "Attributes:\n",
       "- model (nn.Module): The main neural network.\n",
       "- learning_rate (float): Learning rate used for optimization.\n",
       "- cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
       "- train_mse, val_mse, test_mse (torchmetrics.MeanSquaredError): Metrics for computing the mean squared error during training, validation, and testing respectively."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningModel\n",
       "\n",
       ">      LightningModel (model, learning_rate, cosine_t_max)\n",
       "\n",
       "A custom PyTorch Lightning model designed for the encapsulation of training, validation, and testing logic of a neural network.\n",
       "\n",
       "Attributes:\n",
       "- model (nn.Module): The main neural network.\n",
       "- learning_rate (float): Learning rate used for optimization.\n",
       "- cosine_t_max (int): Maximum number of iterations for the cosine annealing scheduler.\n",
       "- train_mse, val_mse, test_mse (torchmetrics.MeanSquaredError): Metrics for computing the mean squared error during training, validation, and testing respectively."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LightningModel._shared_step\n",
       "\n",
       ">      LightningModel._shared_step (batch, debug=False)\n",
       "\n",
       "A shared method for computation during training, validation, and testing.\n",
       "\n",
       "Args:\n",
       "    batch (tuple): Input data batch.\n",
       "    debug (bool, optional): If set to True, the method will print the loss value. Defaults to False.\n",
       "\n",
       "Returns:\n",
       "    tuple: Computed loss, actual labels, and predicted labels."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LightningModel._shared_step\n",
       "\n",
       ">      LightningModel._shared_step (batch, debug=False)\n",
       "\n",
       "A shared method for computation during training, validation, and testing.\n",
       "\n",
       "Args:\n",
       "    batch (tuple): Input data batch.\n",
       "    debug (bool, optional): If set to True, the method will print the loss value. Defaults to False.\n",
       "\n",
       "Returns:\n",
       "    tuple: Computed loss, actual labels, and predicted labels."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LightningModel._shared_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphericDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for atmospheric data and runoff prediction.\n",
    "    \n",
    "    Attributes:\n",
    "    - input_size (int): Length of the input sequence.\n",
    "    - atmosphericStats (tuple): Mean and standard deviation of the atmospheric data along the time dimension.\n",
    "    - runoffDataStats (tuple): Mean and standard deviation of the runoff data along the time dimension.\n",
    "    - x (torch.Tensor): Normalized atmospheric data tensor with dimensions (time, channel, lat, lon).\n",
    "    - y (torch.Tensor): Normalized runoff data tensor with dimensions (time, river).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, atmosphericData, runoff, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the AtmosphericDataset.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Length of the input sequence.\n",
    "            atmosphericData (xr.DataArray): Atmospheric data with dimensions (time, lat, lon).\n",
    "            runoff (xr.DataArray): Runoff data with dimensions (time, river).\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "\n",
    "        # Length of the sequence\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Computing statistics for normalization\n",
    "        atmosphericDataStd = atmosphericData.std(\"time\")\n",
    "        atmosphericDataMean = atmosphericData.mean(\"time\")\n",
    "        self.atmosphericStats = (atmosphericDataMean, atmosphericDataStd)\n",
    "\n",
    "        runoffData = runoff.transpose(\"time\", \"river\")\n",
    "        runoffDataMean = runoffData.mean(\"time\")\n",
    "        runoffDataSTD = runoffData.std(\"time\")\n",
    "        self.runoffDataStats = (runoffDataMean, runoffDataSTD)\n",
    "\n",
    "        # Normalizing the data\n",
    "        X = ((atmosphericData - atmosphericDataMean) / atmosphericDataStd).compute()\n",
    "        y = ((runoffData - runoffDataMean) / runoffDataSTD).compute()\n",
    "\n",
    "        # An additional dimension for the channel is added\n",
    "        xStacked = X.to_array(dim='variable')\n",
    "        xStacked = xStacked.transpose(\"time\", \"variable\", \"y\", \"x\")\n",
    "\n",
    "        assert xStacked.data.ndim == 4\n",
    "        self.x = torch.tensor(xStacked.data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.data, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieves the atmospheric data and corresponding runoff for a given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the data.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing atmospheric data tensor and the corresponding runoff tensor.\n",
    "        \"\"\"\n",
    "        return self.x[index:index+(self.input_size)], self.y[index+int(self.input_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retrieves the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The length of the dataset.\n",
    "        \"\"\"\n",
    "        return self.y.shape[0] - (self.input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AtmosphericDataset\n",
       "\n",
       ">      AtmosphericDataset (input_size, atmosphericData, runoff, transform=None)\n",
       "\n",
       "Dataset for atmospheric data and runoff prediction.\n",
       "\n",
       "Attributes:\n",
       "- input_size (int): Length of the input sequence.\n",
       "- atmosphericStats (tuple): Mean and standard deviation of the atmospheric data along the time dimension.\n",
       "- runoffDataStats (tuple): Mean and standard deviation of the runoff data along the time dimension.\n",
       "- x (torch.Tensor): Normalized atmospheric data tensor with dimensions (time, channel, lat, lon).\n",
       "- y (torch.Tensor): Normalized runoff data tensor with dimensions (time, river)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AtmosphericDataset\n",
       "\n",
       ">      AtmosphericDataset (input_size, atmosphericData, runoff, transform=None)\n",
       "\n",
       "Dataset for atmospheric data and runoff prediction.\n",
       "\n",
       "Attributes:\n",
       "- input_size (int): Length of the input sequence.\n",
       "- atmosphericStats (tuple): Mean and standard deviation of the atmospheric data along the time dimension.\n",
       "- runoffDataStats (tuple): Mean and standard deviation of the runoff data along the time dimension.\n",
       "- x (torch.Tensor): Normalized atmospheric data tensor with dimensions (time, channel, lat, lon).\n",
       "- y (torch.Tensor): Normalized runoff data tensor with dimensions (time, river)."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AtmosphericDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AtmosphereDataModule(L.LightningDataModule):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning DataModule for preparing and loading atmospheric and runoff datasets.\n",
    "    \n",
    "    Attributes:\n",
    "        data (xr.DataArray): The atmospheric data.\n",
    "        runoff (xr.DataArray): The runoff data corresponding to the atmospheric data.\n",
    "        batch_size (int): The batch size for the DataLoader.\n",
    "        num_workers (int): Number of subprocesses to use for data loading.\n",
    "        add_first_dim (bool): Flag to determine if a first dimension needs to be added. (Not used in current implementation).\n",
    "        input_size (int): The input sequence length for the `AtmosphericDataset`.\n",
    "        train (Dataset): Training dataset.\n",
    "        val (Dataset): Validation dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, atmosphericData, runoff, batch_size=64, num_workers=8, add_first_dim=True, input_size=30):\n",
    "        \"\"\"\n",
    "        Initializes the AtmosphereDataModule.\n",
    "\n",
    "        Args:\n",
    "            atmosphericData (xr.DataArray): The atmospheric data.\n",
    "            runoff (xr.DataArray): The runoff data.\n",
    "            batch_size (int, optional): The batch size for data loading. Defaults to 64.\n",
    "            num_workers (int, optional): Number of subprocesses to use for data loading. Defaults to 8.\n",
    "            add_first_dim (bool, optional): Flag to determine if a first dimension should be added. Defaults to True.\n",
    "            input_size (int, optional): The input sequence length for the `AtmosphericDataset`. Defaults to 30.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = atmosphericData\n",
    "        self.runoff = runoff\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.add_first_dim = add_first_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def setup(self, stage:str):\n",
    "        \"\"\"\n",
    "        Sets up the datasets for training and validation.\n",
    "\n",
    "        Args:\n",
    "            stage (str): The stage for which the setup is done (e.g., 'train', 'test', 'predict', etc.).\n",
    "        \"\"\"\n",
    "        UserWarning(\"Loading atmospheric data ...\")\n",
    "        dataset = AtmosphericDataset(\n",
    "            atmosphericData=self.data,\n",
    "            runoff=self.runoff,\n",
    "            input_size=self.input_size\n",
    "        )\n",
    "        n_samples = len(dataset)\n",
    "        train_size = int(0.85 * n_samples)\n",
    "        val_size = n_samples - train_size\n",
    "\n",
    "        # Split the dataset into training and validation subsets\n",
    "        self.train, self.val, = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Prepares and returns the training DataLoader.\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The DataLoader for training data.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True, \n",
    "            drop_last=True, \n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False  # Speed up data transfer to GPU\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Prepares and returns the validation DataLoader.\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The DataLoader for validation data.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "            pin_memory=False  # Speed up data transfer to GPU\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### AtmosphereDataModule\n",
       "\n",
       ">      AtmosphereDataModule (atmosphericData, runoff, batch_size=64,\n",
       ">                            num_workers=8, add_first_dim=True, input_size=30)\n",
       "\n",
       "A PyTorch Lightning DataModule for preparing and loading atmospheric and runoff datasets.\n",
       "\n",
       "Attributes:\n",
       "    data (xr.DataArray): The atmospheric data.\n",
       "    runoff (xr.DataArray): The runoff data corresponding to the atmospheric data.\n",
       "    batch_size (int): The batch size for the DataLoader.\n",
       "    num_workers (int): Number of subprocesses to use for data loading.\n",
       "    add_first_dim (bool): Flag to determine if a first dimension needs to be added. (Not used in current implementation).\n",
       "    input_size (int): The input sequence length for the `AtmosphericDataset`.\n",
       "    train (Dataset): Training dataset.\n",
       "    val (Dataset): Validation dataset."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### AtmosphereDataModule\n",
       "\n",
       ">      AtmosphereDataModule (atmosphericData, runoff, batch_size=64,\n",
       ">                            num_workers=8, add_first_dim=True, input_size=30)\n",
       "\n",
       "A PyTorch Lightning DataModule for preparing and loading atmospheric and runoff datasets.\n",
       "\n",
       "Attributes:\n",
       "    data (xr.DataArray): The atmospheric data.\n",
       "    runoff (xr.DataArray): The runoff data corresponding to the atmospheric data.\n",
       "    batch_size (int): The batch size for the DataLoader.\n",
       "    num_workers (int): Number of subprocesses to use for data loading.\n",
       "    add_first_dim (bool): Flag to determine if a first dimension needs to be added. (Not used in current implementation).\n",
       "    input_size (int): The input sequence length for the `AtmosphericDataset`.\n",
       "    train (Dataset): Training dataset.\n",
       "    val (Dataset): Validation dataset."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(AtmosphereDataModule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
