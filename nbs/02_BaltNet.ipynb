{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp BaltNet\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from BalticRiverPrediction.convLSTM import ConvLSTM\n",
    "from BalticRiverPrediction.sharedUtilities import read_netcdfs, preprocess, plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaltNet(nn.Module):\n",
    "    def __init__(self, modelPar):\n",
    "        super(BaltNet, self).__init__()\n",
    "\n",
    "        # initialize all attributes\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.linear_dim = self.dimensions[0]*self.dimensions[1]*self.hidden_dim\n",
    "\n",
    "        self.convLSTM = ConvLSTM(\n",
    "                input_dim=self.input_dim,\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                kernel_size=self.kernel_size,\n",
    "                num_layers=self.num_layers,\n",
    "                batch_first=self.batch_first,\n",
    "                bias=self.bias,\n",
    "                return_all_layers=self.return_all_layers\n",
    "        )\n",
    "\n",
    "        self.convLSTM2 = ConvLSTM(\n",
    "                input_dim=self.input_dim,\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                kernel_size=self.kernel_size,\n",
    "                num_layers=1,\n",
    "                batch_first=self.batch_first,\n",
    "                bias=self.bias,\n",
    "                return_all_layers=self.return_all_layers\n",
    "        )\n",
    "\n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.linear_dim, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, encode_state = self.convLSTM(x)\n",
    "        decoder_out, _ = self.convLSTM2(x[:,-1:,:,:,:], encode_state)\n",
    "        x = decoder_out[0]\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x).squeeze()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self, modelPar):\n",
    "        super(BaseLineModel, self).__init__()\n",
    "\n",
    "        # initialize all attributes\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.linear_dim = self.dimensions[0]*self.dimensions[1]*self.hidden_dim*self.input_dim\n",
    "\n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.linear_dim, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class LighningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, cosine_t_max):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.cosine_t_max = cosine_t_max\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.val_mse = torchmetrics.MeanSquaredError()\n",
    "        self.test_mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _shared_step(self, batch, debug=False):\n",
    "        features, true_labels = batch\n",
    "        logits = self.model(features)\n",
    "        loss = F.mse_loss(logits, true_labels)\n",
    "        if debug == True:\n",
    "            print(loss)\n",
    "        return loss, true_labels, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch, debug=False)\n",
    "        mse = self.train_mse(predicted_labels, true_labels)\n",
    "        metrics = {\"train_mse\":mse, \"train_loss\":loss}\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True,logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labes, predicted_labels = self._shared_step(batch)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "        self.val_mse(predicted_labels, true_labes)\n",
    "        self.log(\n",
    "            \"val_mse\", self.val_mse, prog_bar=True, sync_dist=True\n",
    "        )\n",
    "    \n",
    "    def test_step(self, batch, _):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        self.test_mse(predicted_labels, true_labels)\n",
    "        self.log(\"test_loss\", loss, rank_zero_only=True)\n",
    "        self.log(\"test_mse\", self.test_mse, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:\n",
    "        _, _, predicted_labels = self._shared_step(batch)\n",
    "        return predicted_labels\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=self.cosine_t_max)\n",
    "\n",
    "        return [opt], [sch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphericDataset(Dataset):\n",
    "    def __init__(self, datapath, transform=None):\n",
    "\n",
    "        data = read_netcdfs(\n",
    "            files=f\"{datapath}/atmosphericForcing/????/rain.mom.dta.nc\",\n",
    "            dim=\"time\",\n",
    "            transform_func=lambda ds:preprocess(ds)\n",
    "            )       \n",
    "        labels = xr.open_mfdataset(f\"{datapath}/runoffData/combined_fastriver_001.nc\")\n",
    "        runoff = labels.roflux.resample(time=\"1D\").mean()\n",
    "\n",
    "        rainData = data[\"RAIN\"]\n",
    "        runoffData = runoff.sel(time=slice(str(rainData.time.min().data), str(rainData.time.max().data)))\n",
    "        X = (rainData - rainData.mean())/rainData.std()\n",
    "        y = (runoffData - runoffData.mean())/runoffData.std()\n",
    "\n",
    "        # TODO \n",
    "        # add dummy dimension in only one atmospheric data file\n",
    "        # is loaded\n",
    "        X = torch.tensor(X.compute().data, dtype=torch.float32)\n",
    "        X = X.unsqueeze(dim=0)\n",
    "        \n",
    "        self.x = X\n",
    "        self.y = torch.tensor(y.compute().data, dtype=torch.float32).flatten()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[:, index:index+30], self.y[index+30]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]-30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphereDataModule(L.LightningDataModule):\n",
    "    def __init__(self, datapath, batch_size=64, num_workers=8, add_first_dim=True):\n",
    "        super().__init__()\n",
    "        self.data_dir = datapath\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.add_first_dim = add_first_dim\n",
    "\n",
    "    def setup(self, stage:str):\n",
    "        UserWarning(\"Loading atmospheric data ...\")\n",
    "        dataset = AtmosphericDataset(datapath=self.data_dir)\n",
    "        n_samples = len(dataset)\n",
    "        train_size = int(0.8 * n_samples)\n",
    "        val_size = int(0.1 * n_samples)\n",
    "        test_size = n_samples - train_size - val_size\n",
    "        self.train, self.val, self.test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True, \n",
    "            drop_last=True, \n",
    "            num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers, \n",
    "            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our GPU has tensor cores, hence mixed precision training is enabled\n",
    "# see https://sebastianraschka.com/blog/2023/llm-mixed-precision-copy.html\n",
    "# for more\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.pytorch.seed_everything(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly inspect if $\\Delta t$ in the data changes. If not simply resampling should do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f77268b60d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datapath = \"/silor/boergel/paper/runoff_prediction/data\"\n",
    "labels = xr.open_mfdataset(f\"{datapath}/runoffData/combined_fastriver_005.nc\")\n",
    "labels.time.diff(\"time\").diff(\"time\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = AtmosphereDataModule(\n",
    "    datapath=\"/silor/boergel/paper/runoff_prediction/data\",\n",
    "    batch_size=64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParameters = {\n",
    "    \"input_dim\":30, # timesteps\n",
    "    \"hidden_dim\":1, # Channels -> right now only precipitation\n",
    "    \"kernel_size\":(3,3), # applied for spatial convolutions\n",
    "    \"num_layers\":2, # number of convLSTM layers\n",
    "    \"batch_first\":True, # first index is batch\n",
    "    \"bias\":True, \n",
    "    \"return_all_layers\": False, \n",
    "    \"dimensions\": (191, 206) # dimensions of atmospheric forcing\n",
    "}\n",
    "\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTorchBaltNet = BaltNet(modelPar=modelParameters)\n",
    "LighningBaltNet = LighningModel(pyTorchBaltNet, learning_rate=1e-3, cosine_t_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"val_mse\", save_last=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=2,\n",
    "    logger=CSVLogger(save_dir=\"/silor/boergel/paper/runoff_prediction/logs\", name=\"BaltNet1\"),\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 123\n",
      "[rank: 1] Global seed set to 123\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 54/54 [01:20<00:00,  1.49s/it]\n",
      "100%|██████████| 54/54 [01:52<00:00,  2.08s/it]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | BaltNet          | 10.1 M\n",
      "1 | train_mse | MeanSquaredError | 0     \n",
      "2 | val_mse   | MeanSquaredError | 0     \n",
      "3 | test_mse  | MeanSquaredError | 0     \n",
      "-----------------------------------------------\n",
      "10.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.1 M    Total params\n",
      "40.302    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 123/123 [00:16<00:00,  7.24it/s, v_num=43, train_mse_step=0.261, train_loss_step=0.261, val_mse=0.427]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('train_mse', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n",
      "/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  14%|█▍        | 17/123 [00:02<00:16,  6.44it/s, v_num=43, train_mse_step=0.0246, train_loss_step=0.0246, val_mse=0.0681, train_mse_epoch=0.0391, train_loss_epoch=0.0391] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  63%|██████▎   | 77/123 [00:09<00:05,  8.07it/s, v_num=43, train_mse_step=0.0607, train_loss_step=0.0607, val_mse=0.0531, train_mse_epoch=0.030, train_loss_epoch=0.030]  "
     ]
    }
   ],
   "source": [
    "trainer.fit(model=LighningBaltNet, datamodule=dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 123\n",
      "[rank: 1] Global seed set to 123\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "100%|██████████| 54/54 [01:30<00:00,  1.67s/it]\n",
      "100%|██████████| 54/54 [01:31<00:00,  1.69s/it]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:226: PossibleUserWarning: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 15/15 [00:03<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/silos/conda_packages/boergel/miniconda3_4.12.0/OS_15.4/conda_env/BaltNet/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:432: PossibleUserWarning: It is recommended to use `self.log('test_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 15/15 [00:03<00:00,  3.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4748583436012268     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4527163803577423     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4748583436012268    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4527163803577423    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.4748583436012268, 'test_mse': 0.4527163803577423}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=LighningBaltNet, datamodule=dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
