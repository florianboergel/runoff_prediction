{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp BaltNet\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaltNet\n",
    "\n",
    "Model architecture used for predicting river runoff in the Baltic Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from BalticRiverPrediction.convLSTM import ConvLSTM\n",
    "from BalticRiverPrediction.sharedUtilities import read_netcdfs, preprocess, plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaltNet(nn.Module):\n",
    "    def __init__(self, modelPar):\n",
    "        super(BaltNet, self).__init__()\n",
    "\n",
    "        # initialize all attributes\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.linear_dim = self.dimensions[0]*self.dimensions[1]*self.hidden_dim\n",
    "\n",
    "        self.convLSTM = ConvLSTM(\n",
    "                input_dim=self.input_dim,\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                kernel_size=self.kernel_size,\n",
    "                num_layers=self.num_layers,\n",
    "                batch_first=self.batch_first,\n",
    "                bias=self.bias,\n",
    "                return_all_layers=self.return_all_layers\n",
    "        )\n",
    "\n",
    "        self.convLSTM2 = ConvLSTM(\n",
    "                input_dim=self.input_dim,\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                kernel_size=self.kernel_size,\n",
    "                num_layers=1,\n",
    "                batch_first=self.batch_first,\n",
    "                bias=self.bias,\n",
    "                return_all_layers=self.return_all_layers\n",
    "        )\n",
    "\n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.linear_dim, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 97)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, encode_state = self.convLSTM(x)\n",
    "        decoder_out, _ = self.convLSTM2(x[:,-1:,:,:,:], encode_state)\n",
    "        x = decoder_out[0]\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x).squeeze()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self, modelPar):\n",
    "        super(BaseLineModel, self).__init__()\n",
    "\n",
    "        # initialize all attributes\n",
    "        for k, v in modelPar.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        self.linear_dim = self.dimensions[0]*self.dimensions[1]*self.hidden_dim*self.input_dim\n",
    "\n",
    "        self.fc_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.linear_dim, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc_layers(x).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate, cosine_t_max):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.cosine_t_max = cosine_t_max\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.val_mse = torchmetrics.MeanSquaredError()\n",
    "        self.test_mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _shared_step(self, batch, debug=False):\n",
    "        features, true_labels = batch\n",
    "        logits = self.model(features)\n",
    "        loss = F.mse_loss(logits, true_labels)\n",
    "        if debug == True:\n",
    "            print(loss)\n",
    "        return loss, true_labels, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch, debug=False)\n",
    "        mse = self.train_mse(predicted_labels, true_labels)\n",
    "        metrics = {\"train_mse\":mse, \"train_loss\":loss}\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True,logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, true_labes, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.val_mse(predicted_labels, true_labes)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "        self.log(\"val_mse\", mse, prog_bar=True, sync_dist=True)\n",
    "    \n",
    "    def test_step(self, batch, _):\n",
    "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
    "        mse = self.test_mse(predicted_labels, true_labels)\n",
    "        self.log(\"test_loss\", loss, rank_zero_only=True)\n",
    "        self.log(\"test_mse\", mse, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):\n",
    "        _, _, predicted_labels = self._shared_step(batch)\n",
    "        return predicted_labels\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, eta_min=1e-7, T_max=self.cosine_t_max)\n",
    "\n",
    "        return [opt], [sch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphericDataset(Dataset):\n",
    "    def __init__(self, input_size, atmosphericData, runoff, transform=None):\n",
    "\n",
    "        # Update 6.10.2023\n",
    "        # The function is not handling the preprocessing anymore\n",
    "        # which makes the function more flexible \n",
    "        # Following the technical description of the river data (Germo et al.)\n",
    "        # the original river data is limited to 1979 to 2011\n",
    "        # start_year, end_year = 1979, 2011\n",
    "        # self.timeRange = slice(str(start_year), str(end_year))\n",
    "        \n",
    "        # Length of the sequence\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # input data (x) \n",
    "        atmosphericDataStd = atmosphericData.std(\"time\") # dimension will be channel, lat, lon\n",
    "        atmosphericDataMean = atmosphericData.mean(\"time\")\n",
    "        self.atmosphericStats = (atmosphericDataMean, atmosphericDataStd)\n",
    "\n",
    "        # output data - label (y)\n",
    "        runoffData = runoff.transpose(\"time\", \"river\")\n",
    "        runoffDataMean = runoffData.mean(\"time\")\n",
    "        runoffDataSTD = runoffData.std(\"time\")\n",
    "        self.runoffData = (runoffDataMean, runoffDataSTD)\n",
    "\n",
    "        # save data\n",
    "        np.savetxt(\n",
    "            \"/silor/boergel/paper/runoff_prediction/data/modelStats.txt\",\n",
    "            [runoffDataMean, runoffDataSTD]\n",
    "        )\n",
    "        \n",
    "        # normalize data\n",
    "        X = ((atmosphericData - atmosphericDataMean)/atmosphericDataStd).compute()\n",
    "        y = ((runoffData - runoffDataMean)/runoffDataSTD).compute()\n",
    "        \n",
    "        # If only 3 dimension are available (time, lat, lon) \n",
    "        # an additional dimension for the channel is added\n",
    "        # to end up with (time, channel, lat, lon)\n",
    "\n",
    "        xStacked = X.to_array(dim='variable')\n",
    "        xStacked = xStacked.transpose(\"time\", \"variable\", \"lat\", \"lon\")\n",
    "\n",
    "        if len(xStacked.data.ndim) == 3:\n",
    "            self.x = torch.tensor(xStacked.data, dtype=torch.float32).unsqueeze(dim=1)\n",
    "        else:\n",
    "            assert len(xStacked.data.ndim) == 4\n",
    "            self.x = torch.tensor(xStacked.data, dtype=torch.float32)\n",
    "       \n",
    "        self.y = torch.tensor(y.data, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[:, index:index+(self.input_size)], self.y[index+int(self.input_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]-(self.input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AtmosphereDataModule(L.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, atmosphericData, runoff, batch_size=64, num_workers=8, add_first_dim=True, input_size=30):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = atmosphericData\n",
    "        self.runoff = runoff\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.add_first_dim = add_first_dim\n",
    "        self.input_size = input_size\n",
    "    \n",
    "    def setup(self, stage:str):\n",
    "        UserWarning(\"Loading atmospheric data ...\")\n",
    "        dataset = AtmosphericDataset(\n",
    "            atmosphericData=self.data,\n",
    "            runoff=self.runoff,\n",
    "            input_size=self.input_size\n",
    "            )\n",
    "        n_samples = len(dataset)\n",
    "        train_size = int(0.9 * n_samples)\n",
    "        val_size = n_samples - train_size\n",
    "        self.train, self.val, = random_split(dataset, [train_size, val_size])\n",
    "        # val_size = int(0.1 * n_samples)\n",
    "        # test_size = n_samples - train_size  - val_size\n",
    "        # self.train, self.val, self.test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True, \n",
    "            drop_last=True, \n",
    "            num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True)\n",
    "\n",
    "    # def test_dataloader(self):\n",
    "    #     return DataLoader(\n",
    "    #         self.test,\n",
    "    #         batch_size=self.batch_size,\n",
    "    #         shuffle=False,\n",
    "    #         num_workers=self.num_workers, \n",
    "    #         drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
